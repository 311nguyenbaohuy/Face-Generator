{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install tensorflow-gpu==2.1.0-rc0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport random\nimport cv2 as cv\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom IPython import display\nimport time","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path_to_file = '/kaggle/input/100k/100k'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Create list of paths to iamge**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nDATASET = []\nfor f in os.listdir(path_to_file):\n    path = os.path.join(path_to_file, f)\n    DATASET.append(path)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Read images when training each batch**"},{"metadata":{"trusted":true},"cell_type":"code","source":"DATASET_SIZE = len(DATASET)\nBATCH_SIZE = 128\nSTEP_PER_EPOCH = DATASET_SIZE // BATCH_SIZE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_batch(dataset):\n    lst_files = random.choices(dataset, k=BATCH_SIZE)\n    batch = []\n    for path in lst_files:\n        image = cv.imread(DATASET[0])\n        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n        image = cv.resize(image, (128,128))\n        batch.append(image)\n    \n    batch = np.asarray(batch)\n    normalized_batch = (batch / 127.5) - 1.0\n    return tf.cast(tf.convert_to_tensor(normalized_batch), dtype=tf.float32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sample input\nsample = get_batch(DATASET)\nsample.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Define discriminator/generator model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_discriminator_model():\n  model = tf.keras.Sequential()\n  model.add(tf.keras.layers.Conv2D(64, (5,5), strides=(2,2), padding='same', \n                                   input_shape=(128,128,3)))\n  model.add(tf.keras.layers.LeakyReLU())\n  model.add(tf.keras.layers.Dropout(0.3))\n\n  model.add(tf.keras.layers.Conv2D(128, (5,5), strides=(2,2), padding='same'))\n  model.add(tf.keras.layers.LeakyReLU())\n  model.add(tf.keras.layers.Dropout(0.3))\n\n  model.add(tf.keras.layers.Conv2D(256, (5,5), strides=(2,2), padding='same'))\n  model.add(tf.keras.layers.LeakyReLU())\n  model.add(tf.keras.layers.Dropout(0.3))\n    \n  model.add(tf.keras.layers.Conv2D(512, (5,5), strides=(1,1), padding='same'))\n  model.add(tf.keras.layers.LeakyReLU())\n  model.add(tf.keras.layers.Dropout(0.3))\n\n  model.add(tf.keras.layers.Conv2D(1024, (5,5), strides=(2,2), padding='same'))\n  model.add(tf.keras.layers.LeakyReLU())\n  model.add(tf.keras.layers.Dropout(0.3))\n    \n  model.add(tf.keras.layers.Flatten())\n  model.add(tf.keras.layers.Dense(1))\n  \n  return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"discriminator = create_discriminator_model()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# smple input\ndiscriminator(sample, training=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_generator_model():\n    model = tf.keras.models.Sequential()\n    model.add(tf.keras.layers.Dense(8*8*1024, input_shape=(1000,)))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.LeakyReLU())\n    \n    model.add(tf.keras.layers.Reshape((8,8,1024)))\n    assert model.output_shape == (None, 8, 8, 1024)\n    \n    model.add(tf.keras.layers.Conv2DTranspose(512, (5,5), strides=(2,2), padding='same'))\n    assert model.output_shape == (None, 16, 16, 512)\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.LeakyReLU())\n    \n    model.add(tf.keras.layers.Conv2DTranspose(256, (5,5), strides=(2,2), padding='same'))\n    assert model.output_shape == (None, 32, 32, 256)\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.LeakyReLU())\n    \n    model.add(tf.keras.layers.Conv2DTranspose(128, (5,5), strides=(2,2), padding='same'))\n    assert model.output_shape == (None, 64, 64, 128)\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.LeakyReLU())\n\n    model.add(tf.keras.layers.Conv2DTranspose(64, (5,5), strides=(2,2), padding='same'))\n    assert model.output_shape == (None, 128, 128, 64)\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.LeakyReLU())\n    \n    model.add(tf.keras.layers.Conv2DTranspose(3, (5,5), strides=(1,1), padding='same', activation='tanh'))\n    assert model.output_shape == (None, 128, 128, 3)\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generator = create_generator_model()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# smple input\nnoise = tf.random.uniform((1, 1000))\ngenerated_image = generator(noise, training=False)\ndiscriminator(generated_image, training=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow((generated_image[0] + 1.0) * 127.5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Define loss function**"},{"metadata":{"trusted":true},"cell_type":"code","source":"cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def discriminator_loss(real_output, fake_output):\n    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n    total_loss = real_loss + fake_loss\n    \n    return total_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generator_loss(fake_output):\n    return cross_entropy(tf.ones_like(fake_output), fake_output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generator_optimizer = tf.keras.optimizers.Adam(1e-4)\ndiscriminator_optimizer = tf.keras.optimizers.Adam(1e-4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Checkpoint**"},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint_dir = '/kaggle/output/training'\ncheckpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\ncheckpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n                                 discriminator_optimizer=discriminator_optimizer,\n                                 generator=generator,\n                                 discriminator=discriminator)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Training**"},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS = 10000\nnoise_dim = 1000\nnum_examples_to_generate = 16\n\nseed = tf.random.normal([num_examples_to_generate, noise_dim])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@tf.function\ndef train_step(images):\n    \n    noise = tf.random.uniform((BATCH_SIZE, noise_dim))\n    \n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n        generated_images = generator(noise, training=True)\n        \n        real_output = discriminator(images, training=True)\n        fake_output = discriminator(generated_images, training=True)\n        \n        gen_loss = generator_loss(fake_output)\n        disc_loss = discriminator_loss(real_output, fake_output)\n    \n    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n    \n    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_images(model, epoch, test_input):\n  pred = model(test_input, training=False)\n\n  fig = plt.figure(figsize=(4,4))\n\n  for i in range(pred.shape[0]):\n    plt.subplot(4, 4, i+1)\n    plt.imshow(pred[i, :, :, 0], cmap='gray')\n    plt.axis('off')\n  plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(dataset, epochs):\n    for epoch in range(epochs):\n        start = time.time()\n        for step in range(STEP_PER_EPOCH):\n            batch = get_batch(dataset)\n            train_step(batch)\n        \n        display.clear_output(wait=True)\n        generated_image(generator, epoch, seed)\n        if (epoch + 1) % 20 == 0:\n          checkpoint.save(file_prefix = checkpoint_prefix)\n        print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n    display.clear_output(wait=True)\n    generated_image(generator, epoch, seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train(DATASET, EPOCHS)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}